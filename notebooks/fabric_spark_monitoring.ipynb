{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aef5c8f",
   "metadata": {},
   "source": [
    "# Fabric Spark Monitoring with Log Analytics Integration\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to collect Spark application data, logs, and metrics from Microsoft Fabric using the new Spark Monitoring APIs and ingest them into Azure Monitor Log Analytics.\n",
    "\n",
    "### What This Notebook Does\n",
    "1. **Collect Spark Applications**: List all Spark applications in a workspace\n",
    "2. **Collect Application Details**: Get detailed metrics and resource usage\n",
    "3. **Collect Logs**: Retrieve driver, executor, and Livy logs\n",
    "4. **Collect Metrics**: Get performance metrics using Spark History Server APIs\n",
    "5. **Ingest to Log Analytics**: Send all data to Azure Monitor for analysis\n",
    "\n",
    "### Prerequisites\n",
    "- Azure authentication configured (service principal or managed identity)\n",
    "- Log Analytics workspace with DCR-based custom tables\n",
    "- Data Collection Rules (DCR) and Data Collection Endpoint (DCE) configured\n",
    "- Fabric workspace with Spark applications\n",
    "\n",
    "### Value Proposition\n",
    "- **Centralized Monitoring**: All Spark telemetry in Azure Monitor\n",
    "- **Rich Analytics**: KQL queries for performance analysis\n",
    "- **Alerting**: Proactive notifications for job failures or performance issues\n",
    "- **Correlation**: Cross-reference with other Fabric workloads\n",
    "- **Historical Analysis**: Long-term trends and optimization insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d1930",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import FabricLA-Connector components\n",
    "from fabricla_connector import workflows\n",
    "from fabricla_connector.config import validate_config\n",
    "from fabricla_connector.collectors import (\n",
    "    collect_spark_applications_workspace,\n",
    "    collect_spark_applications_item,\n",
    "    collect_spark_logs,\n",
    "    collect_spark_metrics\n",
    ")\n",
    "\n",
    "print(\"üì¶ FabricLA-Connector modules imported successfully\")\n",
    "print(\"üîó Spark Monitoring API integration ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c408fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and validation\n",
    "print(\"‚öôÔ∏è Validating configuration...\")\n",
    "\n",
    "# Validate all configuration sections\n",
    "config_status = validate_config(\"all\")\n",
    "print(f\"Configuration Status: {'‚úÖ Valid' if config_status else '‚ùå Invalid'}\")\n",
    "\n",
    "# Set workspace ID (update with your workspace ID)\n",
    "WORKSPACE_ID = os.getenv(\"FABRIC_WORKSPACE_ID\", \"your-workspace-id-here\")\n",
    "\n",
    "if WORKSPACE_ID == \"your-workspace-id-here\":\n",
    "    print(\"‚ö†Ô∏è Please update WORKSPACE_ID with your actual Fabric workspace ID\")\n",
    "else:\n",
    "    print(f\"üéØ Target workspace: {WORKSPACE_ID}\")\n",
    "\n",
    "# Configuration for data collection\n",
    "LOOKBACK_HOURS = 24  # How far back to look for Spark applications\n",
    "MAX_APPLICATIONS = 50  # Maximum number of applications to process\n",
    "INCLUDE_LOGS = True  # Whether to collect detailed logs\n",
    "INCLUDE_METRICS = True  # Whether to collect performance metrics\n",
    "\n",
    "print(f\"üìä Collection settings:\")\n",
    "print(f\"   Lookback: {LOOKBACK_HOURS} hours\")\n",
    "print(f\"   Max applications: {MAX_APPLICATIONS}\")\n",
    "print(f\"   Include logs: {INCLUDE_LOGS}\")\n",
    "print(f\"   Include metrics: {INCLUDE_METRICS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e733ca",
   "metadata": {},
   "source": [
    "## Spark Applications Collection\n",
    "\n",
    "### Workspace-Level Spark Applications\n",
    "Collect all Spark applications running in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45625ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect workspace-level Spark applications\n",
    "print(\"üöÄ Collecting workspace-level Spark applications...\")\n",
    "\n",
    "results = workflows.collect_and_ingest_spark_applications(\n",
    "    workspace_id=WORKSPACE_ID,\n",
    "    lookback_hours=LOOKBACK_HOURS,\n",
    "    max_items=MAX_APPLICATIONS\n",
    ")\n",
    "\n",
    "print(f\"\\nüìã Workspace Spark Applications Results:\")\n",
    "print(f\"   Collected: {results['collected']}\")\n",
    "print(f\"   Ingested: {results['ingested']}\")\n",
    "print(f\"   Errors: {len(results['errors'])}\")\n",
    "\n",
    "if results['errors']:\n",
    "    print(\"\\n‚ùå Errors encountered:\")\n",
    "    for error in results['errors'][:3]:  # Show first 3 errors\n",
    "        print(f\"   - {error}\")\n",
    "\n",
    "# Store results for later use\n",
    "workspace_spark_results = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a47c7",
   "metadata": {},
   "source": [
    "### Item-Level Spark Applications\n",
    "Collect Spark applications for specific items (notebooks, Spark job definitions, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fca2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Collect Spark applications for a specific notebook\n",
    "# Update these with your actual item IDs if you want to test item-level collection\n",
    "\n",
    "SAMPLE_NOTEBOOK_ID = os.getenv(\"SAMPLE_NOTEBOOK_ID\")\n",
    "SAMPLE_SPARK_JOB_ID = os.getenv(\"SAMPLE_SPARK_JOB_ID\")\n",
    "\n",
    "item_results = []\n",
    "\n",
    "if SAMPLE_NOTEBOOK_ID:\n",
    "    print(f\"üöÄ Collecting Spark applications for notebook {SAMPLE_NOTEBOOK_ID}...\")\n",
    "    \n",
    "    notebook_results = workflows.collect_and_ingest_spark_item_applications(\n",
    "        workspace_id=WORKSPACE_ID,\n",
    "        item_id=SAMPLE_NOTEBOOK_ID,\n",
    "        item_type=\"notebook\",\n",
    "        lookback_hours=LOOKBACK_HOURS\n",
    "    )\n",
    "    \n",
    "    item_results.append((\"notebook\", notebook_results))\n",
    "    print(f\"   Notebook apps - Collected: {notebook_results['collected']}, Ingested: {notebook_results['ingested']}\")\n",
    "\n",
    "if SAMPLE_SPARK_JOB_ID:\n",
    "    print(f\"üöÄ Collecting Spark applications for Spark job {SAMPLE_SPARK_JOB_ID}...\")\n",
    "    \n",
    "    job_results = workflows.collect_and_ingest_spark_item_applications(\n",
    "        workspace_id=WORKSPACE_ID,\n",
    "        item_id=SAMPLE_SPARK_JOB_ID,\n",
    "        item_type=\"sparkjobdefinition\",\n",
    "        lookback_hours=LOOKBACK_HOURS\n",
    "    )\n",
    "    \n",
    "    item_results.append((\"sparkjobdefinition\", job_results))\n",
    "    print(f\"   Spark job apps - Collected: {job_results['collected']}, Ingested: {job_results['ingested']}\")\n",
    "\n",
    "if not SAMPLE_NOTEBOOK_ID and not SAMPLE_SPARK_JOB_ID:\n",
    "    print(\"‚ÑπÔ∏è No item IDs configured. Set SAMPLE_NOTEBOOK_ID or SAMPLE_SPARK_JOB_ID environment variables to test item-level collection.\")\n",
    "\n",
    "print(f\"\\nüìä Item-level collection completed: {len(item_results)} items processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67dc310",
   "metadata": {},
   "source": [
    "## Detailed Spark Data Collection\n",
    "\n",
    "### Recent Applications Analysis\n",
    "Get recent applications and collect detailed logs and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cbc5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recent Spark applications for detailed analysis\n",
    "print(\"üîç Analyzing recent Spark applications for detailed data collection...\")\n",
    "\n",
    "recent_applications = []\n",
    "logs_collected = 0\n",
    "metrics_collected = 0\n",
    "\n",
    "# Collect recent applications (last 6 hours)\n",
    "for app in collect_spark_applications_workspace(WORKSPACE_ID, lookback_hours=6, max_items=10):\n",
    "    recent_applications.append(app)\n",
    "\n",
    "print(f\"üìã Found {len(recent_applications)} recent applications\")\n",
    "\n",
    "# Process each application for logs and metrics\n",
    "for i, app in enumerate(recent_applications[:5], 1):  # Process first 5 applications\n",
    "    session_id = app.get(\"SessionId\")\n",
    "    application_id = app.get(\"ApplicationId\")\n",
    "    app_name = app.get(\"ApplicationName\", \"Unknown\")\n",
    "    state = app.get(\"State\", \"Unknown\")\n",
    "    \n",
    "    print(f\"\\nüîç Processing application {i}/5: {app_name} (State: {state})\")\n",
    "    print(f\"   Session ID: {session_id}\")\n",
    "    print(f\"   Application ID: {application_id}\")\n",
    "    \n",
    "    if not session_id:\n",
    "        print(\"   ‚ö†Ô∏è No session ID available, skipping\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Collect logs if enabled\n",
    "        if INCLUDE_LOGS:\n",
    "            print(\"   üìù Collecting logs...\")\n",
    "            log_results = workflows.collect_and_ingest_spark_logs(\n",
    "                workspace_id=WORKSPACE_ID,\n",
    "                session_id=session_id,\n",
    "                log_types=[\"driver\", \"executor\"],  # Collect driver and executor logs\n",
    "                max_lines=100  # Limit log lines for demo\n",
    "            )\n",
    "            logs_collected += log_results[\"collected\"]\n",
    "            print(f\"      Logs collected: {log_results['collected']}\")\n",
    "        \n",
    "        # Collect metrics if enabled and application ID is available\n",
    "        if INCLUDE_METRICS and application_id:\n",
    "            print(\"   üìä Collecting metrics...\")\n",
    "            metrics_results = workflows.collect_and_ingest_spark_metrics(\n",
    "                workspace_id=WORKSPACE_ID,\n",
    "                session_id=session_id,\n",
    "                application_id=application_id\n",
    "            )\n",
    "            metrics_collected += metrics_results[\"collected\"]\n",
    "            print(f\"      Metrics collected: {metrics_results['collected']}\")\n",
    "        elif INCLUDE_METRICS:\n",
    "            print(\"   ‚ö†Ô∏è No application ID available for metrics collection\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error processing application: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n‚úÖ Detailed data collection completed:\")\n",
    "print(f\"   Applications processed: {min(len(recent_applications), 5)}\")\n",
    "print(f\"   Total logs collected: {logs_collected}\")\n",
    "print(f\"   Total metrics collected: {metrics_collected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0198fef",
   "metadata": {},
   "source": [
    "## Comprehensive Spark Monitoring\n",
    "\n",
    "### All-in-One Monitoring Workflow\n",
    "Use the comprehensive monitoring function to collect everything in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b84bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive Spark monitoring\n",
    "print(\"üöÄ Running comprehensive Spark monitoring workflow...\")\n",
    "\n",
    "comprehensive_results = workflows.comprehensive_spark_monitoring(\n",
    "    workspace_id=WORKSPACE_ID,\n",
    "    lookback_hours=LOOKBACK_HOURS,\n",
    "    include_logs=INCLUDE_LOGS,\n",
    "    include_metrics=INCLUDE_METRICS,\n",
    "    max_applications=MAX_APPLICATIONS,\n",
    "    max_log_lines=500\n",
    ")\n",
    "\n",
    "print(f\"\\nüìã Comprehensive Monitoring Results:\")\n",
    "print(f\"   Applications collected: {comprehensive_results['applications_collected']}\")\n",
    "print(f\"   Logs collected: {comprehensive_results['logs_collected']}\")\n",
    "print(f\"   Metrics collected: {comprehensive_results['metrics_collected']}\")\n",
    "print(f\"   Total records ingested: {comprehensive_results['total_ingested']}\")\n",
    "print(f\"   Errors: {len(comprehensive_results['errors'])}\")\n",
    "\n",
    "if comprehensive_results['errors']:\n",
    "    print(\"\\n‚ùå Errors encountered:\")\n",
    "    for error in comprehensive_results['errors'][:3]:\n",
    "        print(f\"   - {error}\")\n",
    "\n",
    "# Store results for summary\n",
    "final_results = comprehensive_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0543ac9",
   "metadata": {},
   "source": [
    "## Results Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all data collection activities\n",
    "print(\"üìä SPARK MONITORING SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_collected = (\n",
    "    workspace_spark_results.get('collected', 0) +\n",
    "    sum(result[1].get('collected', 0) for result in item_results) +\n",
    "    logs_collected +\n",
    "    metrics_collected\n",
    ")\n",
    "\n",
    "total_ingested = (\n",
    "    workspace_spark_results.get('ingested', 0) +\n",
    "    sum(result[1].get('ingested', 0) for result in item_results) +\n",
    "    final_results.get('total_ingested', 0)\n",
    ")\n",
    "\n",
    "print(f\"üéØ Workspace: {WORKSPACE_ID}\")\n",
    "print(f\"‚è∞ Time range: Last {LOOKBACK_HOURS} hours\")\n",
    "print(f\"üìà Total records collected: {total_collected}\")\n",
    "print(f\"üì§ Total records ingested: {total_ingested}\")\n",
    "print(f\"\\nüìã Breakdown by category:\")\n",
    "print(f\"   ‚Ä¢ Workspace applications: {workspace_spark_results.get('collected', 0)}\")\n",
    "print(f\"   ‚Ä¢ Item applications: {sum(result[1].get('collected', 0) for result in item_results)}\")\n",
    "print(f\"   ‚Ä¢ Log entries: {logs_collected}\")\n",
    "print(f\"   ‚Ä¢ Metrics: {metrics_collected}\")\n",
    "\n",
    "print(f\"\\nüîó Data ingested to Log Analytics:\")\n",
    "print(f\"   ‚Ä¢ Table: {os.getenv('LOG_ANALYTICS_TABLE', 'CustomTable_CL')}\")\n",
    "print(f\"   ‚Ä¢ Workspace: {os.getenv('LOG_ANALYTICS_WORKSPACE_ID', 'your-workspace-id')}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Spark monitoring integration completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadaf37c",
   "metadata": {},
   "source": [
    "## KQL Queries for Analysis\n",
    "\n",
    "### Sample KQL Queries\n",
    "Use these queries in Azure Monitor to analyze your Spark data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample KQL queries for analyzing Spark data in Log Analytics\n",
    "table_name = os.getenv('LOG_ANALYTICS_TABLE', 'FabricOperational_CL')\n",
    "\n",
    "kql_queries = {\n",
    "    \"Spark Applications Overview\": f\"\"\"\n",
    "// Get overview of Spark applications in the last 24 hours\n",
    "{table_name}\n",
    "| where TimeGenerated > ago(24h)\n",
    "| where MetricType == \"SparkApplication\"\n",
    "| summarize \n",
    "    Applications = count(),\n",
    "    Completed = countif(State == \"success\"),\n",
    "    Failed = countif(State == \"error\"),\n",
    "    Running = countif(State == \"running\")\n",
    "| extend SuccessRate = round(Completed * 100.0 / Applications, 2)\n",
    "\"\"\",\n",
    "\n",
    "    \"Top Resource-Intensive Applications\": f\"\"\"\n",
    "// Find applications using the most resources\n",
    "{table_name}\n",
    "| where TimeGenerated > ago(24h)\n",
    "| where MetricType == \"SparkApplication\"\n",
    "| where isnotnull(ExecutorCount) and isnotnull(ExecutorCores)\n",
    "| extend TotalCores = ExecutorCount * ExecutorCores\n",
    "| top 10 by TotalCores desc\n",
    "| project \n",
    "    ApplicationName,\n",
    "    State,\n",
    "    SubmissionTime,\n",
    "    ExecutorCount,\n",
    "    ExecutorCores,\n",
    "    TotalCores,\n",
    "    ExecutorMemory\n",
    "\"\"\",\n",
    "\n",
    "    \"Failed Applications Analysis\": f\"\"\"\n",
    "// Analyze failed Spark applications\n",
    "{table_name}\n",
    "| where TimeGenerated > ago(24h)\n",
    "| where MetricType == \"SparkApplication\" and State == \"error\"\n",
    "| summarize FailureCount = count() by ApplicationName\n",
    "| order by FailureCount desc\n",
    "\"\"\",\n",
    "\n",
    "    \"Spark Logs Analysis\": f\"\"\"\n",
    "// Analyze Spark log patterns\n",
    "{table_name}\n",
    "| where TimeGenerated > ago(24h)\n",
    "| where MetricType == \"SparkLog\"\n",
    "| where LogMessage contains \"ERROR\" or LogMessage contains \"WARN\"\n",
    "| summarize ErrorCount = count() by LogType, bin(TimeGenerated, 1h)\n",
    "| order by TimeGenerated desc\n",
    "\"\"\",\n",
    "\n",
    "    \"Performance Metrics Trends\": f\"\"\"\n",
    "// Analyze Spark performance metrics over time\n",
    "{table_name}\n",
    "| where TimeGenerated > ago(24h)\n",
    "| where MetricType == \"SparkMetric\" and MetricCategory == \"Executor\"\n",
    "| summarize \n",
    "    AvgMemoryUsed = avg(MemoryUsed),\n",
    "    AvgActiveTasks = avg(ActiveTasks),\n",
    "    TotalFailedTasks = sum(FailedTasks)\n",
    "    by bin(TimeGenerated, 1h)\n",
    "| order by TimeGenerated desc\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "print(\"üìä Sample KQL Queries for Spark Data Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for query_name, query in kql_queries.items():\n",
    "    print(f\"\\nüîç {query_name}:\")\n",
    "    print(query.strip())\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(f\"\\nüí° Tips for Analysis:\")\n",
    "print(f\"   ‚Ä¢ Use these queries in Azure Monitor Log Analytics\")\n",
    "print(f\"   ‚Ä¢ Create custom dashboards and alerts\")\n",
    "print(f\"   ‚Ä¢ Adjust time ranges as needed\")\n",
    "print(f\"   ‚Ä¢ Combine with other Fabric metrics for comprehensive analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e8559",
   "metadata": {},
   "source": [
    "## Integration with Fabric Diagnostic Emitter\n",
    "\n",
    "### How This Complements the Fabric Spark Diagnostic Emitter\n",
    "\n",
    "This connector works alongside Fabric's built-in Spark Diagnostic Emitter:\n",
    "\n",
    "1. **Real-time Streaming (Diagnostic Emitter)**:\n",
    "   - Automatically streams logs during Spark execution\n",
    "   - Direct integration with Event Hubs, Storage, or Log Analytics\n",
    "   - No additional code required\n",
    "\n",
    "2. **Historical Analysis (This Connector)**:\n",
    "   - Retrospective analysis using Monitoring APIs\n",
    "   - Rich metadata and application context\n",
    "   - Cross-workspace correlation\n",
    "   - Business logic and KPI calculation\n",
    "\n",
    "3. **Combined Value**:\n",
    "   - Complete operational picture\n",
    "   - Real-time alerts + historical trends\n",
    "   - Technical metrics + business insights\n",
    "\n",
    "### Next Steps\n",
    "1. Configure Fabric Diagnostic Emitter for real-time streaming\n",
    "2. Schedule this connector for regular historical collection\n",
    "3. Create unified dashboards in Azure Monitor\n",
    "4. Set up alerting rules for proactive monitoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
